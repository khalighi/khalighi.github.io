# Doing No Harm: The Imperative for an AI Practitioner’s Ethical Code

**Date: Jan 22, 2024**

![DALL-E depiction of Hippocratic Oath for AI practitioners](/images/dalle_hippocratic_oath.jpg)

In the dynamic landscape of technological innovation, few areas have shown as much promise and potential for transformation as artificial intelligence (AI).

Like many, I’ve been a proponent of the immense benefits AI can bring. However, as we integrate AI deeper into the fabric of daily life, it’s crucial that we address an emerging necessity: the need for AI practitioners to adopt an ethical code akin to the Hippocratic Oath in medicine. Key elements that might be included in such an oath are:

1. **Do No Harm**: Prioritizing the safety and well-being of humans and the environment, ensuring that AI technologies do not cause harm.
2. **Promote Fairness**: Striving for fairness and avoiding biases in AI algorithms, ensuring that AI applications are inclusive and equitable.
3. **Respect Privacy**: Upholding the privacy rights of individuals, ensuring that AI technologies are not used to infringe upon personal privacy.
4. **Transparency**: Committing to transparency in AI systems, making it clear how AI decisions are made and on what basis.
5. **Accountability**: Taking responsibility for the impacts of AI systems and being accountable for the decisions made by AI.
6. **Continuous Learning**: Engaging in ongoing learning about the ethical implications of AI and adapting practices as the field evolves.
7. **Collaboration**: Working collaboratively with other stakeholders, including policymakers, to ensure responsible development and deployment of AI.
8. **Public Interest**: Ensuring that AI is used for the public good, contributing positively to society and not just serving private interests.

The notion of “doing no harm” is more than a moral compass; it’s a practical guideline that needs to be at the heart of AI development. The consequences of AI are far-reaching, influencing everything from healthcare and environmental sustainability to privacy and social justice. The ethical deployment of AI thus becomes not just a technical issue but a societal imperative.

Take, for instance, the realm of healthcare, an area I am deeply passionate about. AI has the potential to revolutionize medical diagnostics and treatment, offering personalized care and new insights into complex diseases. However, without a guiding ethical principle, the same technology could exacerbate existing inequalities or compromise patient privacy.

Transparency and accountability are crucial in this journey. AI’s decision-making processes can often be opaque, making it difficult for users and regulators to understand how conclusions are reached. An ethical framework would encourage AI developers to prioritize explainability in their algorithms, fostering trust and making technology more accessible and understandable to all.

Moreover, as AI evolves, so should our approach to privacy and consent. The vast amounts of personal data used by AI systems pose significant privacy risks. Practitioners must treat this data with the utmost respect, using it responsibly and ensuring robust consent mechanisms. This isn’t just about legal compliance; it’s about building a foundation of trust with users.

One of the lessons I’ve learned in my career is the importance of continual learning and adaptation. The field of AI is no exception. What is considered ethical and safe today may not be tomorrow. Practitioners must commit to staying informed and evolving their practices in line with new discoveries and societal shifts.

Finally, and perhaps most importantly, is the commitment to inclusivity and diversity. The data and perspectives that feed AI algorithms greatly influence their outputs. A lack of diversity in AI development teams can lead to biases in AI systems, perpetuating societal disparities. It is imperative that AI practitioners strive for diversity in both their teams and their data, ensuring equitable and fair outcomes.

In sum, as we continue to harness the transformative power of AI, it is paramount that those at its forefront commit to an ethical framework. “Doing no harm” should be more than a guiding principle; it should be a foundational aspect of AI development and deployment. This is not just about preventing negative outcomes but about ensuring that AI is a positive force for humanity, enhancing our lives while safeguarding our values and rights. As we look towards a future increasingly shaped by AI, let us ensure that this technology is synonymous with trust, safety, and the greater good of society.